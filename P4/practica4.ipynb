{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3a5b998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo base 'yolo11n.pt' cargado correctamente.\n",
      "New https://pypi.org/project/ultralytics/8.3.223 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.215  Python-3.9.23 torch-2.8.0+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=matriculas.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=70, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=modelo_matriculas_yolo11, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\lucia\\OneDrive\\Escritorio\\uniDUNIA_2\\4CURSO\\VC\\VC\\P4\\runs\\detect\\modelo_matriculas_yolo11, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.30.1 ms, read: 218.6104.7 MB/s, size: 473.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\lucia\\OneDrive\\Escritorio\\uniDUNIA_2\\4CURSO\\VC\\VC\\P4\\TGC_RBNW\\train\\labels.cache... 141 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 141/141  0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\lucia\\OneDrive\\Escritorio\\uniDUNIA_2\\4CURSO\\VC\\VC\\P4\\TGC_RBNW\\train\\images\\4037KMN.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\lucia\\OneDrive\\Escritorio\\uniDUNIA_2\\4CURSO\\VC\\VC\\P4\\TGC_RBNW\\train\\images\\4786FWR.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\lucia\\OneDrive\\Escritorio\\uniDUNIA_2\\4CURSO\\VC\\VC\\P4\\TGC_RBNW\\train\\images\\4990BMC_4786FWR.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\lucia\\OneDrive\\Escritorio\\uniDUNIA_2\\4CURSO\\VC\\VC\\P4\\TGC_RBNW\\train\\images\\C0336BVY.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\lucia\\OneDrive\\Escritorio\\uniDUNIA_2\\4CURSO\\VC\\VC\\P4\\TGC_RBNW\\train\\images\\GC0265BF.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.30.2 ms, read: 243.171.0 MB/s, size: 506.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\lucia\\OneDrive\\Escritorio\\uniDUNIA_2\\4CURSO\\VC\\VC\\P4\\TGC_RBNW\\val\\labels.cache... 40 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 40/40  0.0s\n",
      "Plotting labels to C:\\Users\\lucia\\OneDrive\\Escritorio\\uniDUNIA_2\\4CURSO\\VC\\VC\\P4\\runs\\detect\\modelo_matriculas_yolo11\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\lucia\\OneDrive\\Escritorio\\uniDUNIA_2\\4CURSO\\VC\\VC\\P4\\runs\\detect\\modelo_matriculas_yolo11\u001b[0m\n",
      "Starting training for 70 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/70         0G      1.386      3.675       1.24          2        640: 100% ━━━━━━━━━━━━ 36/36 0.3it/s 2:172.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.6it/s 8.0s2.2ss\n",
      "                   all         40         48    0.00275      0.688      0.277      0.174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/70         0G      1.472      2.786      1.227          1        640: 100% ━━━━━━━━━━━━ 36/36 0.4it/s 1:361.9sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.6it/s 7.8s2.2ss\n",
      "                   all         40         48      0.567      0.146      0.216     0.0984\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/70         0G      1.552      2.634      1.224          2        640: 100% ━━━━━━━━━━━━ 36/36 0.4it/s 1:362.0sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.6it/s 7.7s2.2ss\n",
      "                   all         40         48      0.726      0.331      0.394      0.225\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/70         0G      1.594      2.583      1.273          1        640: 100% ━━━━━━━━━━━━ 36/36 0.4it/s 1:291.8sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.8it/s 6.4s1.8ss\n",
      "                   all         40         48      0.209      0.303       0.18     0.0944\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/70         0G      1.486      2.537      1.194          1        640: 100% ━━━━━━━━━━━━ 36/36 0.5it/s 1:181.3sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.8it/s 6.6s1.9ss\n",
      "                   all         40         48      0.388      0.396      0.271      0.152\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/70         0G      1.467      2.383       1.17          2        640: 100% ━━━━━━━━━━━━ 36/36 0.1it/s 9:051.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.8it/s 6.6s1.9ss\n",
      "                   all         40         48      0.421      0.354      0.288      0.152\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/70         0G      1.465      2.357        1.2          2        640: 100% ━━━━━━━━━━━━ 36/36 0.5it/s 1:161.3sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.8it/s 6.2s1.7ss\n",
      "                   all         40         48      0.672      0.426      0.466      0.248\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/70         0G      1.462      2.024      1.188          4        640: 100% ━━━━━━━━━━━━ 36/36 0.1it/s 6:431.7sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.6it/s 8.3s2.3ss\n",
      "                   all         40         48      0.488      0.496      0.464      0.254\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/70         0G      1.346      1.986      1.128          2        640: 100% ━━━━━━━━━━━━ 36/36 0.4it/s 1:241.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.7it/s 6.7s1.9ss\n",
      "                   all         40         48      0.525      0.417      0.456      0.235\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/70         0G      1.298      1.716      1.085          2        640: 100% ━━━━━━━━━━━━ 36/36 0.5it/s 1:191.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.8it/s 6.5s1.8ss\n",
      "                   all         40         48      0.713      0.479      0.584      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/70         0G      1.227      1.674      1.111          3        640: 100% ━━━━━━━━━━━━ 36/36 0.5it/s 1:141.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.8it/s 6.3s1.8ss\n",
      "                   all         40         48      0.499      0.643      0.516      0.323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/70         0G      1.256      1.589      1.115          2        640: 100% ━━━━━━━━━━━━ 36/36 0.2it/s 3:371.6sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.8it/s 6.4s1.8ss\n",
      "                   all         40         48      0.539      0.646      0.573      0.341\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/70         0G      1.224      1.561      1.055          2        640: 100% ━━━━━━━━━━━━ 36/36 0.5it/s 1:161.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.8it/s 6.5s1.8ss\n",
      "                   all         40         48       0.76      0.708      0.745      0.408\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/70         0G      1.245      1.622      1.084          3        640: 100% ━━━━━━━━━━━━ 36/36 0.1it/s 9:231.8sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.8it/s 6.6s1.9ss\n",
      "                   all         40         48      0.742      0.708      0.718      0.462\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/70         0G      1.185      1.534      1.057          0        640: 100% ━━━━━━━━━━━━ 36/36 0.5it/s 1:191.3sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.8it/s 6.4s1.8ss\n",
      "                   all         40         48      0.523      0.707      0.552      0.349\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/70         0G      1.199      1.431      1.096          1        640: 100% ━━━━━━━━━━━━ 36/36 0.5it/s 1:191.9sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.5it/s 10.7s.1ss\n",
      "                   all         40         48      0.872      0.667      0.741      0.464\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/70         0G       1.13      1.408      1.038          2        640: 100% ━━━━━━━━━━━━ 36/36 0.1it/s 7:410.9ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.2it/s 4.3s1.2ss\n",
      "                   all         40         48      0.824      0.604      0.689      0.472\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/70         0G       1.14      1.259      1.034          4        640: 100% ━━━━━━━━━━━━ 36/36 0.7it/s 49.3s0.9ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.2it/s 4.3s1.2ss\n",
      "                   all         40         48       0.79      0.626      0.655      0.438\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/70         0G      1.107      1.294      1.038          2        640: 100% ━━━━━━━━━━━━ 36/36 0.7it/s 54.2s1.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.0it/s 4.8s1.4ss\n",
      "                   all         40         48      0.914      0.663      0.727      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/70         0G      1.105      1.244      1.031          2        640: 100% ━━━━━━━━━━━━ 36/36 0.7it/s 52.3s0.9ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.1it/s 4.5s1.3ss\n",
      "                   all         40         48      0.786      0.708      0.753      0.482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/70         0G      1.092       1.17      1.011          1        640: 100% ━━━━━━━━━━━━ 36/36 0.6it/s 1:051.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.9it/s 5.8s1.6ss\n",
      "                   all         40         48      0.883      0.628      0.751      0.518\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/70         0G      1.072      1.128      1.034          3        640: 100% ━━━━━━━━━━━━ 36/36 0.6it/s 56.3s1.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.0it/s 4.8s1.4ss\n",
      "                   all         40         48      0.968      0.623      0.757      0.517\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/70         0G      1.048      1.109      1.009          1        640: 100% ━━━━━━━━━━━━ 36/36 0.7it/s 55.0s1.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.1it/s 4.7s1.3ss\n",
      "                   all         40         48      0.864      0.708      0.761      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/70         0G      1.092      1.113     0.9979          2        640: 100% ━━━━━━━━━━━━ 36/36 0.7it/s 55.1s1.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.0it/s 4.9s1.4ss\n",
      "                   all         40         48      0.874      0.625      0.746      0.494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/70         0G      1.068      1.144      1.018          4        640: 100% ━━━━━━━━━━━━ 36/36 0.6it/s 55.9s1.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.0it/s 4.8s1.4ss\n",
      "                   all         40         48      0.892      0.646      0.754      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/70         0G       1.05      1.067     0.9812          3        640: 100% ━━━━━━━━━━━━ 36/36 0.6it/s 1:031.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.0it/s 4.9s1.4ss\n",
      "                   all         40         48      0.774      0.667      0.737      0.523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/70         0G      1.075      1.038      1.041          2        640: 100% ━━━━━━━━━━━━ 36/36 0.7it/s 55.2s1.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.1it/s 4.7s1.3ss\n",
      "                   all         40         48          1      0.726      0.828      0.577\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/70         0G      1.034      1.012     0.9872          5        640: 100% ━━━━━━━━━━━━ 36/36 0.7it/s 54.9s1.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.0it/s 4.8s1.3ss\n",
      "                   all         40         48      0.971      0.689       0.78      0.549\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/70         0G      1.017     0.9778     0.9885          3        640: 100% ━━━━━━━━━━━━ 36/36 0.7it/s 54.6s1.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.0it/s 5.1s1.4ss\n",
      "                   all         40         48       0.91      0.708      0.791      0.563\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/70         0G     0.9532     0.9856     0.9714          3        640: 100% ━━━━━━━━━━━━ 36/36 0.6it/s 55.8s1.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.9it/s 5.5s1.5ss\n",
      "                   all         40         48      0.947      0.646      0.769      0.525\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/70         0G     0.9747     0.9527      0.991          1        640: 100% ━━━━━━━━━━━━ 36/36 0.6it/s 1:011.0sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.1it/s 4.7s1.3ss\n",
      "                   all         40         48      0.896      0.722      0.798      0.525\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/70         0G      1.031      1.029      1.024          1        640: 100% ━━━━━━━━━━━━ 36/36 0.7it/s 54.4s0.9ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.1it/s 4.7s1.3ss\n",
      "                   all         40         48      0.857       0.75      0.808      0.536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/70         0G     0.9498     0.8941     0.9875          4        640: 100% ━━━━━━━━━━━━ 36/36 0.7it/s 54.5s1.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.0it/s 4.8s1.4ss\n",
      "                   all         40         48      0.848      0.729      0.804       0.56\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/70         0G     0.9591     0.8856     0.9783          1        640: 100% ━━━━━━━━━━━━ 36/36 0.7it/s 54.7s1.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.1it/s 4.7s1.3ss\n",
      "                   all         40         48      0.864      0.688      0.789      0.544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/70         0G     0.8973     0.8815     0.9482          2        640: 100% ━━━━━━━━━━━━ 36/36 0.6it/s 56.2s1.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.9it/s 5.3s1.5ss\n",
      "                   all         40         48      0.855      0.739      0.813      0.549\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/70         0G      0.976     0.9511     0.9814          5        640: 100% ━━━━━━━━━━━━ 36/36 0.6it/s 59.1s1.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.1it/s 4.7s1.4ss\n",
      "                   all         40         48       0.97      0.684      0.799      0.566\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/70         0G     0.9465      0.935     0.9142          0        640: 100% ━━━━━━━━━━━━ 36/36 0.7it/s 54.0s1.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.0it/s 4.8s1.3ss\n",
      "                   all         40         48      0.919      0.706      0.818      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/70         0G     0.9503     0.8457     0.9526          4        640: 100% ━━━━━━━━━━━━ 36/36 0.7it/s 54.4s1.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.1it/s 4.7s1.3ss\n",
      "                   all         40         48      0.921      0.728      0.828      0.574\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/70         0G      0.949     0.8593     0.9901          2        640: 100% ━━━━━━━━━━━━ 36/36 0.7it/s 54.3s1.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.1it/s 4.7s1.3ss\n",
      "                   all         40         48      0.883      0.783      0.828      0.582\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/70         0G     0.9137     0.7763      0.937          2        640: 100% ━━━━━━━━━━━━ 36/36 0.6it/s 58.1s1.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.9it/s 5.4s1.5ss\n",
      "                   all         40         48      0.991      0.729      0.836      0.596\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/70         0G     0.9358       0.89      0.957          1        640: 100% ━━━━━━━━━━━━ 36/36 0.4it/s 1:251.3sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.8it/s 6.2s1.8ss\n",
      "                   all         40         48          1      0.723      0.835      0.597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/70         0G     0.8721     0.7921      0.927          2        640: 100% ━━━━━━━━━━━━ 36/36 0.6it/s 1:041.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.9it/s 5.3s1.5ss\n",
      "                   all         40         48      0.989      0.729      0.837      0.596\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/70         0G     0.8936     0.8275     0.9555          1        640: 100% ━━━━━━━━━━━━ 36/36 0.6it/s 58.9s1.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.1it/s 4.7s1.3ss\n",
      "                   all         40         48      0.928      0.771      0.845      0.628\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/70         0G      0.882      0.829      0.931          3        640: 100% ━━━━━━━━━━━━ 36/36 0.7it/s 54.3s1.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.1it/s 4.7s1.3ss\n",
      "                   all         40         48       0.94      0.792      0.841      0.617\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/70         0G     0.9585     0.8676     0.9733          2        640: 100% ━━━━━━━━━━━━ 36/36 0.7it/s 54.2s1.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.1it/s 4.7s1.3ss\n",
      "                   all         40         48      0.858      0.771      0.819      0.586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/70         0G     0.8718     0.8183     0.9408          4        640: 100% ━━━━━━━━━━━━ 36/36 0.6it/s 55.4s1.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.1it/s 4.7s1.3ss\n",
      "                   all         40         48      0.882      0.771      0.828      0.599\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/70         0G     0.9116     0.7668     0.9435          1        640: 100% ━━━━━━━━━━━━ 36/36 0.6it/s 56.0s1.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.0it/s 4.8s1.4ss\n",
      "                   all         40         48      0.949       0.77      0.839      0.611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/70         0G     0.8035     0.7117     0.9104          1        640: 100% ━━━━━━━━━━━━ 36/36 0.6it/s 58.1s1.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.9it/s 5.4s1.5ss\n",
      "                   all         40         48      0.855      0.792      0.833      0.625\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/70         0G     0.9028     0.7774     0.9549          3        640: 100% ━━━━━━━━━━━━ 36/36 0.4it/s 1:282.3sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.5it/s 9.7s2.7ss\n",
      "                   all         40         48      0.878      0.792      0.831      0.634\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/70         0G     0.9012     0.8111     0.9472          2        640: 100% ━━━━━━━━━━━━ 36/36 0.3it/s 1:521.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.5it/s 9.1s2.5ss\n",
      "                   all         40         48      0.926      0.787      0.829      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      51/70         0G     0.8822     0.7462       0.93          3        640: 100% ━━━━━━━━━━━━ 36/36 0.3it/s 2:081.8ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.6it/s 8.0s2.2ss\n",
      "                   all         40         48      0.914      0.771      0.831      0.616\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      52/70         0G     0.7276     0.6698     0.9137          2        640: 100% ━━━━━━━━━━━━ 36/36 0.1it/s 4:131.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.0it/s 5.2s1.5ss\n",
      "                   all         40         48      0.922      0.739      0.837      0.637\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      53/70         0G     0.7631     0.7264     0.9033          3        640: 100% ━━━━━━━━━━━━ 36/36 0.6it/s 1:051.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.9it/s 5.5s1.5ss\n",
      "                   all         40         48          1      0.726      0.838      0.642\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      54/70         0G     0.8212     0.7031     0.9141          2        640: 100% ━━━━━━━━━━━━ 36/36 0.5it/s 1:081.2s2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.9it/s 5.5s1.5ss\n",
      "                   all         40         48       0.98      0.729      0.838      0.635\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      55/70         0G     0.7398     0.7083     0.9267          1        640: 100% ━━━━━━━━━━━━ 36/36 0.5it/s 1:081.1s6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.9it/s 5.6s1.6ss\n",
      "                   all         40         48      0.985      0.708      0.832      0.628\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      56/70         0G     0.8248     0.7132     0.9041          1        640: 100% ━━━━━━━━━━━━ 36/36 0.0it/s 13:350.9ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.2it/s 4.0s1.1s\n",
      "                   all         40         48      0.916      0.792      0.845      0.646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      57/70         0G     0.7832     0.6669      0.905          1        640: 100% ━━━━━━━━━━━━ 36/36 0.7it/s 48.6s0.8ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.2it/s 4.3s1.2ss\n",
      "                   all         40         48      0.935      0.792      0.848       0.64\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      58/70         0G     0.7721     0.6899      0.898          3        640: 100% ━━━━━━━━━━━━ 36/36 0.7it/s 50.9s0.9ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.1it/s 4.7s1.3ss\n",
      "                   all         40         48       0.97       0.75       0.85      0.664\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      59/70         0G     0.7643     0.7124     0.9075          0        640: 100% ━━━━━━━━━━━━ 36/36 0.6it/s 55.9s1.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.0it/s 4.8s1.4ss\n",
      "                   all         40         48      0.927      0.791      0.852      0.657\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      60/70         0G     0.7944      0.696     0.9404          1        640: 100% ━━━━━━━━━━━━ 36/36 0.6it/s 56.8s0.9ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.0it/s 4.8s1.4ss\n",
      "                   all         40         48      0.944      0.792      0.852      0.667\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      61/70         0G     0.7034     0.6768     0.8593          1        640: 100% ━━━━━━━━━━━━ 36/36 0.6it/s 1:030.9sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.0it/s 4.8s1.4ss\n",
      "                   all         40         48      0.963       0.75      0.843      0.653\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      62/70         0G     0.6838     0.6701     0.8526          1        640: 100% ━━━━━━━━━━━━ 36/36 0.6it/s 55.4s1.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.1it/s 4.7s1.4ss\n",
      "                   all         40         48      0.923      0.771      0.834      0.647\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      63/70         0G     0.6505     0.6581     0.8518          2        640: 100% ━━━━━━━━━━━━ 36/36 0.6it/s 55.9s1.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.0it/s 4.8s1.4ss\n",
      "                   all         40         48      0.924       0.75      0.836      0.647\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      64/70         0G     0.6786     0.7082     0.8756          1        640: 100% ━━━━━━━━━━━━ 36/36 0.7it/s 54.5s1.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.1it/s 4.8s1.4ss\n",
      "                   all         40         48      0.948      0.767      0.832      0.641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      65/70         0G      0.713     0.6725     0.8601          1        640: 100% ━━━━━━━━━━━━ 36/36 0.6it/s 56.9s1.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 0.9it/s 5.4s1.5ss\n",
      "                   all         40         48      0.922      0.771      0.827      0.647\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      66/70         0G     0.6275     0.6262     0.8448          1        640: 100% ━━━━━━━━━━━━ 36/36 0.0it/s 16:011.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.2it/s 4.2s1.2ss\n",
      "                   all         40         48      0.922      0.771      0.827      0.649\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      67/70         0G     0.6388      0.628     0.8502          1        640: 100% ━━━━━━━━━━━━ 36/36 0.8it/s 48.0s0.9ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.2it/s 4.2s1.2ss\n",
      "                   all         40         48      0.981       0.75       0.83       0.64\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      68/70         0G      0.655     0.6383     0.8563          1        640: 100% ━━━━━━━━━━━━ 36/36 0.7it/s 49.1s0.8ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.1it/s 4.4s1.3ss\n",
      "                   all         40         48      0.995      0.771      0.836      0.644\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      69/70         0G     0.6401     0.6284     0.8267          1        640: 100% ━━━━━━━━━━━━ 36/36 0.7it/s 54.2s0.9ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.1it/s 4.4s1.3ss\n",
      "                   all         40         48      0.987      0.771      0.838       0.65\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      70/70         0G     0.6244     0.6168     0.8347          1        640: 100% ━━━━━━━━━━━━ 36/36 0.7it/s 51.5s1.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.1it/s 4.7s1.4ss\n",
      "                   all         40         48      0.993      0.771      0.838      0.648\n",
      "\n",
      "70 epochs completed in 2.411 hours.\n",
      "Optimizer stripped from C:\\Users\\lucia\\OneDrive\\Escritorio\\uniDUNIA_2\\4CURSO\\VC\\VC\\P4\\runs\\detect\\modelo_matriculas_yolo11\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from C:\\Users\\lucia\\OneDrive\\Escritorio\\uniDUNIA_2\\4CURSO\\VC\\VC\\P4\\runs\\detect\\modelo_matriculas_yolo11\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating C:\\Users\\lucia\\OneDrive\\Escritorio\\uniDUNIA_2\\4CURSO\\VC\\VC\\P4\\runs\\detect\\modelo_matriculas_yolo11\\weights\\best.pt...\n",
      "Ultralytics 8.3.215  Python-3.9.23 torch-2.8.0+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 1.1it/s 4.4s1.2s\n",
      "                   all         40         48      0.944      0.792      0.852      0.667\n",
      "Speed: 1.0ms preprocess, 72.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\lucia\\OneDrive\\Escritorio\\uniDUNIA_2\\4CURSO\\VC\\VC\\P4\\runs\\detect\\modelo_matriculas_yolo11\u001b[0m\n",
      "\n",
      "¡Entrenamiento para SOLO matrículas (base yolo11n) completado!\n",
      "Mejores pesos del modelo guardados en: runs/detect/C:\\Users\\lucia\\OneDrive\\Escritorio\\uniDUNIA_2\\4CURSO\\VC\\VC\\P4\\runs\\detect\\modelo_matriculas_yolo11/weights/best.pt\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# --- 1. Cargar el modelo base yolo11n.pt ---\n",
    "# Asumiendo que tienes este archivo y es compatible.\n",
    "try:\n",
    "    model = YOLO('yolo11n.pt') # Carga los pesos base de yolo11n\n",
    "    print(\"Modelo base 'yolo11n.pt' cargado correctamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error cargando el modelo base 'yolo11n.pt': {e}\")\n",
    "    print(\"Asegúrate de que el archivo existe y es compatible con Ultralytics.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Iniciar Entrenamiento ---\n",
    "# Entrena el modelo usando tu archivo 'matriculas_solo.yaml'\n",
    "# Este YAML DEBE tener nc: 1 y names: ['matricula']\n",
    "results = model.train(\n",
    "    data='matriculas.yaml',    # Ruta al archivo YAML (solo 1 clase: matricula)\n",
    "    epochs=70,                    # Número de épocas (ajusta según necesites)\n",
    "    imgsz=640,                    # Tamaño de imagen\n",
    "    batch=4,                     # Tamaño del lote\n",
    "    name='modelo_matriculas_yolo11', # Nombre para la carpeta de resultados\n",
    "    exist_ok=True                 # Permite sobrescribir\n",
    ")\n",
    "\n",
    "print(\"\\n¡Entrenamiento para SOLO matrículas (base yolo11n) completado!\")\n",
    "# La ruta real donde se guardan los pesos\n",
    "print(f\"Mejores pesos del modelo guardados en: runs/detect/{results.save_dir}/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68f9167f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo general (yolov8n.pt) para coches cargado correctamente.\n",
      "Modelo entrenado para matrículas 'runs/detect/modelo_matriculas_yolo11/weights/best.pt' cargado correctamente.\n",
      "Procesando 6 imágenes...\n",
      "Resultados guardados en: resultados2_deteccion_combinada_y11base\n",
      "\n",
      "Proceso de detección combinada completado.\n",
      "Resultados guardados en: resultados2_deteccion_combinada_y11base\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- CONFIGURACIÓN DE MODELOS, dibujar imagen ---\n",
    "\n",
    "# Carga el modelo general YOLOv8 pre-entrenado (para vehículos)\n",
    "try:\n",
    "    model_general_coches = YOLO('yolov8n.pt') # Usamos yolov8n estándar para coches\n",
    "    print(\"Modelo general (yolov8n.pt) para coches cargado correctamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error cargando modelo general 'yolov8n.pt': {e}\")\n",
    "    exit()\n",
    "\n",
    "# Carga TU modelo entrenado (el que se basó en yolo11n.pt)\n",
    "# ¡¡IMPORTANTE!! Ajusta esta ruta al 'best.pt' del entrenamiento anterior.\n",
    "try:\n",
    "    # Usa el nombre que le diste al entrenamiento ('modelo_matriculas_yolo11')\n",
    "    ruta_modelo_matriculas_entrenado = 'runs/detect/modelo_matriculas_yolo11/weights/best.pt' # <--- AJUSTA ESTA RUTA\n",
    "    model_matriculas = YOLO(ruta_modelo_matriculas_entrenado)\n",
    "    print(f\"Modelo entrenado para matrículas '{ruta_modelo_matriculas_entrenado}' cargado correctamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error cargando tu modelo entrenado de matrículas '{ruta_modelo_matriculas_entrenado}': {e}\")\n",
    "    print(\"Asegúrate de que la ruta apunta al archivo 'best.pt' correcto.\")\n",
    "    exit()\n",
    "\n",
    "# Clases de interés del modelo general (vehículos COCO)\n",
    "coco_vehicle_classes = [2, 3, 5, 7] # car, motorcycle, bus, truck\n",
    "\n",
    "# Colores y confianzas\n",
    "color_vehiculo = (255, 0, 0) # Azul\n",
    "color_matricula = (0, 255, 0) # Verde\n",
    "conf_vehiculo = 0.40\n",
    "conf_matricula = 0.1\n",
    "\n",
    "# --- DEFINIR IMÁGENES DE PRUEBA Y SALIDA ---\n",
    "ruta_carpeta_imagenes_test = './TGC_RBNW/imgenes_comprobar/*'\n",
    "rutas_imagenes_test = glob.glob(ruta_carpeta_imagenes_test)\n",
    "if not rutas_imagenes_test:\n",
    "    print(f\"Error: No se encontraron imágenes en '{ruta_carpeta_imagenes_test}'.\")\n",
    "    exit()\n",
    "output_dir_deteccion_combinada = 'resultados2_deteccion_combinada_y11base'\n",
    "os.makedirs(output_dir_deteccion_combinada, exist_ok=True)\n",
    "\n",
    "print(f\"Procesando {len(rutas_imagenes_test)} imágenes...\")\n",
    "print(f\"Resultados guardados en: {output_dir_deteccion_combinada}\")\n",
    "\n",
    "# --- PROCESAR IMÁGENES Y DIBUJAR ---\n",
    "for img_path in rutas_imagenes_test:\n",
    "    base_filename = os.path.basename(img_path)\n",
    "    # print(f\"Procesando: {base_filename}\") # Puedes descomentar para ver el progreso\n",
    "\n",
    "    frame = cv2.imread(img_path)\n",
    "    if frame is None: continue\n",
    "    frame_annotated = frame.copy()\n",
    "\n",
    "    # --- 1. Detectar VEHÍCULOS ---\n",
    "    results_coches = model_general_coches.predict(frame, classes=coco_vehicle_classes, conf=conf_vehiculo, verbose=False)\n",
    "    if len(results_coches) > 0 and len(results_coches[0].boxes) > 0:\n",
    "        for box_veh in results_coches[0].boxes:\n",
    "            coords_veh = box_veh.xyxy.cpu().numpy().astype(int)[0]\n",
    "            x1_v, y1_v, x2_v, y2_v = coords_veh\n",
    "            conf_v = box_veh.conf.cpu().numpy()[0]\n",
    "            class_id_v = int(box_veh.cls.cpu().numpy()[0])\n",
    "            label_veh = model_general_coches.names[class_id_v]\n",
    "            cv2.rectangle(frame_annotated, (x1_v, y1_v), (x2_v, y2_v), color_vehiculo, 2)\n",
    "            cv2.putText(frame_annotated, f'{label_veh} {conf_v:.2f}', (x1_v, y1_v - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color_vehiculo, 2)\n",
    "\n",
    "    # --- 2. Detectar MATRÍCULAS ---\n",
    "    results_matricula = model_matriculas.predict(frame, conf=conf_matricula, verbose=False)\n",
    "    if len(results_matricula) > 0 and len(results_matricula[0].boxes) > 0:\n",
    "        for box_mat in results_matricula[0].boxes:\n",
    "            coords_mat = box_mat.xyxy.cpu().numpy().astype(int)[0]\n",
    "            mx1, my1, mx2, my2 = coords_mat\n",
    "            conf_m = box_mat.conf.cpu().numpy()[0]\n",
    "            label_mat = model_matriculas.names[0] # Siempre será 'matricula'\n",
    "            cv2.rectangle(frame_annotated, (mx1, my1), (mx2, my2), color_matricula, 2)\n",
    "            cv2.putText(frame_annotated, f'{label_mat} {conf_m:.2f}', (mx1, my1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color_matricula, 2)\n",
    "\n",
    "    # --- GUARDAR ---\n",
    "    output_path = os.path.join(output_dir_deteccion_combinada, f\"comb_{base_filename}\")\n",
    "    cv2.imwrite(output_path, frame_annotated)\n",
    "\n",
    "# --- FINALIZACIÓN ---\n",
    "print(\"\\nProceso de detección combinada completado.\")\n",
    "print(f\"Resultados guardados en: {output_dir_deteccion_combinada}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6ec6e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo general (yolov8n.pt) para coches cargado correctamente.\n",
      "Modelo entrenado para matrículas 'runs/detect/modelo_matriculas_yolo11/weights/best.pt' cargado correctamente.\n",
      "Procesando video: ./input_media/video.mp4...\n",
      "--- ¡Pulsa 'q' en la ventana emergente para salir! ---\n",
      "\n",
      "Proceso de video completado.\n",
      "Video guardado en: ./resultados_video/video_detectado.mp4\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- CONFIGURACIÓN DE MODELOS, dibujar imagen ---\n",
    "try:\n",
    "    model_general_coches = YOLO('yolov8n.pt') \n",
    "    print(\"Modelo general (yolov8n.pt) para coches cargado correctamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error cargando modelo general 'yolov8n.pt': {e}\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    ruta_modelo_matriculas_entrenado = 'runs/detect/modelo_matriculas_yolo11/weights/best.pt'\n",
    "    model_matriculas = YOLO(ruta_modelo_matriculas_entrenado)\n",
    "    print(f\"Modelo entrenado para matrículas '{ruta_modelo_matriculas_entrenado}' cargado correctamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error cargando tu modelo entrenado de matrículas '{ruta_modelo_matriculas_entrenado}': {e}\")\n",
    "    exit()\n",
    "\n",
    "coco_vehicle_classes = [2, 3, 5, 7] # car, motorcycle, bus, truck\n",
    "color_vehiculo = (255, 0, 0) # Azul\n",
    "color_matricula = (0, 255, 0) # Verde\n",
    "conf_vehiculo = 0.40\n",
    "conf_matricula = 0.1\n",
    "\n",
    "# --- DEFINIR VIDEO DE ENTRADA Y SALIDA ---\n",
    "ruta_video_entrada = './input_media/video.mp4' \n",
    "ruta_video_salida = './resultados_video/video_detectado.mp4'\n",
    "os.makedirs('./resultados_video', exist_ok=True) \n",
    "\n",
    "# --- CONFIGURAR LECTURA Y ESCRITURA DE VIDEO ---\n",
    "cap = cv2.VideoCapture(ruta_video_entrada)\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: No se pudo abrir el video '{ruta_video_entrada}'\")\n",
    "    exit()\n",
    "\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "out = cv2.VideoWriter(ruta_video_salida, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "print(f\"Procesando video: {ruta_video_entrada}...\")\n",
    "print(\"--- ¡Pulsa 'q' en la ventana emergente para salir! ---\")\n",
    "\n",
    "# --- PROCESAR VIDEO FRAME A FRAME ---\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_annotated = frame.copy()\n",
    "\n",
    "    # --- 1. Detectar VEHÍCULOS ---\n",
    "    results_coches = model_general_coches.predict(frame, classes=coco_vehicle_classes, conf=conf_vehiculo, verbose=False)\n",
    "    if len(results_coches) > 0 and len(results_coches[0].boxes) > 0:\n",
    "        for box_veh in results_coches[0].boxes:\n",
    "            coords_veh = box_veh.xyxy.cpu().numpy().astype(int)[0]\n",
    "            x1_v, y1_v, x2_v, y2_v = coords_veh\n",
    "            conf_v = box_veh.conf.cpu().numpy()[0]\n",
    "            class_id_v = int(box_veh.cls.cpu().numpy()[0])\n",
    "            label_veh = model_general_coches.names[class_id_v]\n",
    "            cv2.rectangle(frame_annotated, (x1_v, y1_v), (x2_v, y2_v), color_vehiculo, 2)\n",
    "            cv2.putText(frame_annotated, f'{label_veh} {conf_v:.2f}', (x1_v, y1_v - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color_vehiculo, 2)\n",
    "\n",
    "    # --- 2. Detectar MATRÍCULAS ---\n",
    "    results_matricula = model_matriculas.predict(frame, conf=conf_matricula, verbose=False)\n",
    "    if len(results_matricula) > 0 and len(results_matricula[0].boxes) > 0:\n",
    "        for box_mat in results_matricula[0].boxes:\n",
    "            coords_mat = box_mat.xyxy.cpu().numpy().astype(int)[0]\n",
    "            mx1, my1, mx2, my2 = coords_mat\n",
    "            conf_m = box_mat.conf.cpu().numpy()[0]\n",
    "            label_mat = model_matriculas.names[0] \n",
    "            cv2.rectangle(frame_annotated, (mx1, my1), (mx2, my2), color_matricula, 2)\n",
    "            cv2.putText(frame_annotated, f'{label_mat} {conf_m:.2f}', (mx1, my1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color_matricula, 2)\n",
    "\n",
    "    # --- GUARDAR EL FOTOGRAMA PROCESADO ---\n",
    "    out.write(frame_annotated)\n",
    "    \n",
    "    # --- NUEVO: MOSTRAR EL VIDEO EN VENTANA EMERGENTE ---\n",
    "    # Muestra el fotograma anotado en una ventana llamada 'Deteccion en Vivo'\n",
    "    cv2.imshow('Deteccion en Vivo', frame_annotated)\n",
    "\n",
    "    # --- NUEVO: ESPERAR 1ms Y COMPROBAR SI SE PULSA LA TECLA 'q' ---\n",
    "    # Esto es OBLIGATORIO para que cv2.imshow funcione\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Detenido por el usuario.\")\n",
    "        break\n",
    "\n",
    "# --- FINALIZACIÓN ---\n",
    "# Liberar los objetos de video\n",
    "cap.release()\n",
    "out.release()\n",
    "# --- NUEVO: CERRAR TODAS LAS VENTANAS DE OPENCV ---\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"\\nProceso de video completado.\")\n",
    "print(f\"Video guardado en: {ruta_video_salida}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd43bfc",
   "metadata": {},
   "source": [
    "**EASYOCR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd8af615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelos YOLO...\n",
      "Cargando EasyOCR...\n",
      "EasyOCR cargado correctamente (CPU).\n",
      "Procesando 6 imágenes para EasyOCR...\n",
      "  > img_comprobar1.jpg [Conf: 0.95] - EasyOCR: 6628GXR (172.8 ms)\n",
      "  > img_comprobar1.jpg [Conf: 0.30] - EasyOCR: 15532BYP (124.5 ms)\n",
      "  > img_comprobar2.jpg [Conf: 0.84] - EasyOCR: JPGC7085N (157.2 ms)\n",
      "  > img_comprobar3.jpeg [Conf: 0.98] - EasyOCR: E (537.3 ms)\n",
      "  > img_comprobar4.jpg [Conf: 0.91] - EasyOCR: JNV (213.7 ms)\n",
      "  > img_comprobar4.jpg [Conf: 0.57] - EasyOCR: 3232JCJ (112.1 ms)\n",
      "  > img_comprobar4.jpg [Conf: 0.18] - EasyOCR: N/A (70.4 ms)\n",
      "  > img_comprobar5.jpeg [Conf: 0.93] - EasyOCR: JHM (427.8 ms)\n",
      "  > img_comprobar6.jpeg [Conf: 0.94] - EasyOCR: GGAGX7497 (175.2 ms)\n",
      "  > img_comprobar6.jpeg [Conf: 0.21] - EasyOCR: N/A (33.6 ms)\n",
      "\n",
      "--- Proceso EasyOCR completado ---\n",
      "Resultados CSV guardados en: resultados_comparativa_OCR\\easyocr_results.csv\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import csv\n",
    "import easyocr\n",
    "\n",
    "print(\"Cargando modelos YOLO...\")\n",
    "model_general_coches = YOLO('yolov8n.pt')\n",
    "model_matriculas = YOLO('runs/detect/modelo_matriculas_yolo11/weights/best.pt')\n",
    "\n",
    "print(\"Cargando EasyOCR...\")\n",
    "try:\n",
    "    reader_easyocr = easyocr.Reader(['es', 'en'], gpu=False)\n",
    "    print(\"EasyOCR cargado correctamente (CPU).\")\n",
    "except Exception as e:\n",
    "    print(f\"Error cargando easyOCR: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- RUTA CORREGIDA ---\n",
    "ruta_carpeta_imagenes_test = './TGC_RBNW/imgenes_comprobar/*' # <--- ¡Corregido!\n",
    "rutas_imagenes_test = glob.glob(ruta_carpeta_imagenes_test)\n",
    "output_dir_deteccion_combinada = 'resultados_comparativa_OCR'\n",
    "os.makedirs(output_dir_deteccion_combinada, exist_ok=True)\n",
    "\n",
    "csv_output_path = os.path.join(output_dir_deteccion_combinada, 'easyocr_results.csv')\n",
    "csv_results = []\n",
    "csv_header = ['Imagen', 'Conf_Deteccion', 'Matricula_EasyOCR', 'Tiempo_EasyOCR_ms']\n",
    "\n",
    "print(f\"Procesando {len(rutas_imagenes_test)} imágenes para EasyOCR...\")\n",
    "\n",
    "for img_path in rutas_imagenes_test:\n",
    "    base_filename = os.path.basename(img_path)\n",
    "    frame = cv2.imread(img_path)\n",
    "    if frame is None: continue\n",
    "    frame_annotated = frame.copy() \n",
    "\n",
    "    # --- 1. Detectar VEHÍCULOS ---\n",
    "    results_coches = model_general_coches.predict(frame, classes=[2, 3, 5, 7], conf=0.40, verbose=False)\n",
    "    if len(results_coches) > 0 and len(results_coches[0].boxes) > 0:\n",
    "        for box_veh in results_coches[0].boxes:\n",
    "            coords_veh = box_veh.xyxy.cpu().numpy().astype(int)[0]\n",
    "            x1_v, y1_v, x2_v, y2_v = coords_veh\n",
    "            cv2.rectangle(frame_annotated, (x1_v, y1_v), (x2_v, y2_v), (255, 0, 0), 2)\n",
    "\n",
    "    # --- 2. Detectar MATRÍCULAS ---\n",
    "    results_matricula = model_matriculas.predict(frame, conf=0.1, verbose=False)\n",
    "    \n",
    "    if len(results_matricula) > 0 and len(results_matricula[0].boxes) > 0:\n",
    "        for box_mat in results_matricula[0].boxes:\n",
    "            coords_mat = box_mat.xyxy.cpu().numpy().astype(int)[0]\n",
    "            mx1, my1, mx2, my2 = coords_mat\n",
    "            conf_m = box_mat.conf.cpu().numpy()[0]\n",
    "            \n",
    "            matricula_recortada = frame[max(0, my1 - 5):min(frame.shape[0], my2 + 5), max(0, mx1 - 5):min(frame.shape[1], mx2 + 5)]\n",
    "            \n",
    "            texto_easyocr = \"N/A\"\n",
    "            tiempo_easyocr = 0.0\n",
    "\n",
    "            try:\n",
    "                t_start_ocr = time.time()\n",
    "                ocr_result = reader_easyocr.readtext(matricula_recortada, detail=0, allowlist='0123456789ABCDEFGHIJKLMNPQRSTUVWXYZ')\n",
    "                t_end_ocr = time.time()\n",
    "                tiempo_easyocr = (t_end_ocr - t_start_ocr) * 1000\n",
    "                if ocr_result:\n",
    "                    texto_easyocr = ocr_result[0].upper().replace(\" \", \"\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error en EasyOCR: {e}\")\n",
    "                \n",
    "            csv_results.append([base_filename, f\"{conf_m:.2f}\", texto_easyocr, f\"{tiempo_easyocr:.1f}\"])\n",
    "            \n",
    "            cv2.rectangle(frame_annotated, (mx1, my1), (mx2, my2), (0, 255, 0), 2)\n",
    "            label_final = f'{texto_easyocr} ({conf_m:.2f})'\n",
    "            cv2.putText(frame_annotated, label_final, (mx1, my1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            print(f\"  > {base_filename} [Conf: {conf_m:.2f}] - EasyOCR: {texto_easyocr} ({tiempo_easyocr:.1f} ms)\")\n",
    "\n",
    "    output_path = os.path.join(output_dir_deteccion_combinada, f\"easyocr_{base_filename}\")\n",
    "    cv2.imwrite(output_path, frame_annotated)\n",
    "\n",
    "try:\n",
    "    with open(csv_output_path, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(csv_header)\n",
    "        writer.writerows(csv_results)\n",
    "except Exception as e:\n",
    "    print(f\"Error al guardar el CSV: {e}\")\n",
    "\n",
    "print(f\"\\n--- Proceso EasyOCR completado ---\")\n",
    "print(f\"Resultados CSV guardados en: {csv_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969f2aa6",
   "metadata": {},
   "source": [
    "**TESSERACT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f281723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesseract 5.4.0.20240606 cargado correctamente.\n",
      "Cargando modelos YOLO...\n",
      "Procesando 6 imágenes para Tesseract...\n",
      "  > img_comprobar1.jpg [Conf: 0.95] - Tesseract: N/A (111.5 ms)\n",
      "  > img_comprobar1.jpg [Conf: 0.30] - Tesseract: A5532BYP (94.4 ms)\n",
      "  > img_comprobar2.jpg [Conf: 0.84] - Tesseract: IPGC7089N (113.0 ms)\n",
      "  > img_comprobar3.jpeg [Conf: 0.98] - Tesseract: 13168JHM (162.5 ms)\n",
      "  > img_comprobar4.jpg [Conf: 0.91] - Tesseract: N/A (116.6 ms)\n",
      "  > img_comprobar4.jpg [Conf: 0.57] - Tesseract: 3232NC9 (83.5 ms)\n",
      "  > img_comprobar4.jpg [Conf: 0.18] - Tesseract: KA (116.3 ms)\n",
      "  > img_comprobar5.jpeg [Conf: 0.93] - Tesseract: N/A (136.2 ms)\n",
      "  > img_comprobar6.jpeg [Conf: 0.94] - Tesseract: N/A (100.0 ms)\n",
      "  > img_comprobar6.jpeg [Conf: 0.21] - Tesseract: N/A (117.1 ms)\n",
      "\n",
      "--- Proceso Tesseract completado ---\n",
      "Resultados CSV guardados en: resultados_comparativa_OCR\\tesseract_results.csv\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import csv\n",
    "import pytesseract # <-- NUEVO: Importar Tesseract\n",
    "\n",
    "# --- ¡¡IMPORTANTE!! CONFIGURACIÓN DE TESSERACT ---\n",
    "# Tienes que decirle a Python dónde está el archivo .exe que instalaste.\n",
    "# ¡¡AJUSTA ESTA RUTA A LA DE TU ORDENADOR!!\n",
    "try:\n",
    "    pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\lucia\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe'\n",
    "    version = pytesseract.get_tesseract_version()\n",
    "    print(f\"Tesseract {version} cargado correctamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error cargando Tesseract. ¿Instalaste el programa y configuraste bien la ruta?\")\n",
    "    print(f\"Error: {e}\")\n",
    "    # exit() # Descomenta esto si quieres que el script pare si Tesseract falla\n",
    "\n",
    "# --- CONFIGURACIÓN DE MODELOS ---\n",
    "print(\"Cargando modelos YOLO...\")\n",
    "model_general_coches = YOLO('yolov8n.pt')\n",
    "model_matriculas = YOLO('runs/detect/modelo_matriculas_yolo11/weights/best.pt')\n",
    "\n",
    "\n",
    "# --- CONFIGURACIÓN DE RUTAS ---\n",
    "ruta_carpeta_imagenes_test = './TGC_RBNW/imgenes_comprobar/*' # Ruta corregida\n",
    "rutas_imagenes_test = glob.glob(ruta_carpeta_imagenes_test)\n",
    "output_dir_deteccion_combinada = 'resultados_comparativa_OCR'\n",
    "os.makedirs(output_dir_deteccion_combinada, exist_ok=True)\n",
    "\n",
    "# --- CONFIGURACIÓN CSV ---\n",
    "csv_output_path = os.path.join(output_dir_deteccion_combinada, 'tesseract_results.csv')\n",
    "csv_results = []\n",
    "csv_header = ['Imagen', 'Conf_Deteccion', 'Matricula_Tesseract', 'Tiempo_Tesseract_ms']\n",
    "\n",
    "print(f\"Procesando {len(rutas_imagenes_test)} imágenes para Tesseract...\")\n",
    "\n",
    "# --- Configuración de Tesseract para matrículas ---\n",
    "# --psm 7: Trata la imagen como una sola línea de texto.\n",
    "# Whitelist: Solo busca estos caracteres.\n",
    "config_tesseract = '--psm 7 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNPQRSTUVWXYZ'\n",
    "\n",
    "# --- PROCESAR IMÁGENES ---\n",
    "for img_path in rutas_imagenes_test:\n",
    "    base_filename = os.path.basename(img_path)\n",
    "    frame = cv2.imread(img_path)\n",
    "    if frame is None: continue\n",
    "    frame_annotated = frame.copy() \n",
    "\n",
    "    # --- 1. Detectar VEHÍCULOS (Opcional) ---\n",
    "    results_coches = model_general_coches.predict(frame, classes=[2, 3, 5, 7], conf=0.40, verbose=False)\n",
    "    if len(results_coches) > 0 and len(results_coches[0].boxes) > 0:\n",
    "        for box_veh in results_coches[0].boxes:\n",
    "            coords_veh = box_veh.xyxy.cpu().numpy().astype(int)[0]\n",
    "            x1_v, y1_v, x2_v, y2_v = coords_veh\n",
    "            cv2.rectangle(frame_annotated, (x1_v, y1_v), (x2_v, y2_v), (255, 0, 0), 2)\n",
    "\n",
    "    # --- 2. Detectar MATRÍCULAS ---\n",
    "    results_matricula = model_matriculas.predict(frame, conf=0.1, verbose=False)\n",
    "    \n",
    "    if len(results_matricula) > 0 and len(results_matricula[0].boxes) > 0:\n",
    "        for box_mat in results_matricula[0].boxes:\n",
    "            coords_mat = box_mat.xyxy.cpu().numpy().astype(int)[0]\n",
    "            mx1, my1, mx2, my2 = coords_mat\n",
    "            conf_m = box_mat.conf.cpu().numpy()[0]\n",
    "            \n",
    "            matricula_recortada = frame[max(0, my1 - 5):min(frame.shape[0], my2 + 5), max(0, mx1 - 5):min(frame.shape[1], mx2 + 5)]\n",
    "            \n",
    "            texto_tesseract = \"N/A\"\n",
    "            tiempo_tesseract = 0.0\n",
    "\n",
    "            # --- Lógica de Tesseract ---\n",
    "            try:\n",
    "                t_start_ocr = time.time()\n",
    "                # Pasamos la imagen recortada (en formato OpenCV/BGR)\n",
    "                # y la configuración que definimos antes.\n",
    "                texto_tesseract = pytesseract.image_to_string(matricula_recortada, config=config_tesseract)\n",
    "                t_end_ocr = time.time()\n",
    "                tiempo_tesseract = (t_end_ocr - t_start_ocr) * 1000 # en ms\n",
    "                \n",
    "                # Limpiamos el resultado (Tesseract suele añadir saltos de línea \\n o \\f)\n",
    "                texto_tesseract = texto_tesseract.strip().upper().replace(\" \", \"\")\n",
    "                \n",
    "                if not texto_tesseract:\n",
    "                    texto_tesseract = \"N/A\" # Si está vacío, lo marcamos N/A\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error en Tesseract: {e}\")\n",
    "                \n",
    "            csv_results.append([base_filename, f\"{conf_m:.2f}\", texto_tesseract, f\"{tiempo_tesseract:.1f}\"])\n",
    "            \n",
    "            cv2.rectangle(frame_annotated, (mx1, my1), (mx2, my2), (255, 0, 255), 2) # Color Magenta para Tesseract\n",
    "            label_final = f'T: {texto_tesseract} ({conf_m:.2f})'\n",
    "            cv2.putText(frame_annotated, label_final, (mx1, my1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)\n",
    "            print(f\"  > {base_filename} [Conf: {conf_m:.2f}] - Tesseract: {texto_tesseract} ({tiempo_tesseract:.1f} ms)\")\n",
    "\n",
    "    output_path = os.path.join(output_dir_deteccion_combinada, f\"tesseract_{base_filename}\")\n",
    "    cv2.imwrite(output_path, frame_annotated)\n",
    "\n",
    "# --- GUARDAR EL ARCHIVO CSV ---\n",
    "try:\n",
    "    with open(csv_output_path, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(csv_header)\n",
    "        writer.writerows(csv_results)\n",
    "except Exception as e:\n",
    "    print(f\"Error al guardar el CSV: {e}\")\n",
    "\n",
    "print(f\"\\n--- Proceso Tesseract completado ---\")\n",
    "print(f\"Resultados CSV guardados en: {csv_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e1f5df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelos YOLO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos YOLO cargados.\n",
      "Cargando EasyOCR (esto puede tardar un momento)...\n",
      "EasyOCR cargado.\n",
      "Procesando video: ./input_media/video.mp4...\n",
      "--- ¡Pulsa 'q' en la ventana emergente para salir! ---\n",
      "Detenido por el usuario.\n",
      "\n",
      "Limpiando recursos...\n",
      "\n",
      "--- Conteo Final (IDs únicos detectados) ---\n",
      "Total persons: 9\n",
      "Total cars: 24\n",
      "Total motorcycles: 2\n",
      "Total buss: 4\n",
      "Total trucks: 6\n",
      "Total objetos seguidos: 45\n",
      "\n",
      "Proceso de video completado.\n",
      "Video guardado en: ./resultados_video/video_final_con_ocr.mp4\n",
      "Log CSV guardado en: ./resultados_video/log_detecciones.csv\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "\n",
    "# --- 1. CONFIGURACIÓN INICIAL ---\n",
    "\n",
    "# Cargar Modelos YOLO\n",
    "print(\"Cargando modelos YOLO...\")\n",
    "try:\n",
    "    model_general_coches = YOLO('yolov8n.pt')\n",
    "    ruta_modelo_matriculas = 'runs/detect/modelo_matriculas_yolo11/weights/best.pt'\n",
    "    model_matriculas = YOLO(ruta_modelo_matriculas)\n",
    "    print(\"Modelos YOLO cargados.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error cargando modelos YOLO: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Cargar EasyOCR (solo se hace una vez)\n",
    "print(\"Cargando EasyOCR (esto puede tardar un momento)...\")\n",
    "try:\n",
    "    reader_easyocr = easyocr.Reader(['es', 'en'], gpu=False) # False si no tienes GPU\n",
    "    print(\"EasyOCR cargado.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error cargando easyOCR: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Clases de interés (P4): 0=person, 2=car, 3=motorcycle, 5=bus, 7=truck\n",
    "coco_classes_of_interest = [0, 2, 3, 5, 7] \n",
    "\n",
    "# Colores y confianzas\n",
    "color_vehiculo_persona = (255, 0, 0) # Azul\n",
    "color_matricula = (0, 255, 0) # Verde\n",
    "conf_vehiculo = 0.40\n",
    "conf_matricula = 0.1\n",
    "\n",
    "# --- 2. CONFIGURACIÓN DE ENTRADA Y SALIDA ---\n",
    "\n",
    "# Rutas de Vídeo\n",
    "ruta_video_entrada = './input_media/video.mp4'\n",
    "ruta_video_salida = './resultados_video/video_final_con_ocr.mp4'\n",
    "os.makedirs('./resultados_video', exist_ok=True)\n",
    "\n",
    "# Rutas de CSV (P4.6 y P4b)\n",
    "csv_output_path = './resultados_video/log_detecciones.csv'\n",
    "# Definimos el header del CSV\n",
    "csv_header = [\n",
    "    'fotograma', \n",
    "    'tipo_objeto',      # person, car, matricula\n",
    "    'confianza', \n",
    "    'id_tracking',      # 'N/A' para matrículas\n",
    "    'x1', 'y1', 'x2', 'y2', \n",
    "    'texto_matricula'   # 'N/A' para personas/vehículos\n",
    "]\n",
    "\n",
    "# --- 3. INICIALIZAR LECTORES Y ESCRITORES ---\n",
    "\n",
    "# Lector de Video\n",
    "cap = cv2.VideoCapture(ruta_video_entrada)\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: No se pudo abrir el video '{ruta_video_entrada}'\")\n",
    "    exit()\n",
    "\n",
    "# Escritor de Video\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(ruta_video_salida, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Escritor de CSV\n",
    "try:\n",
    "    csv_file = open(csv_output_path, 'w', newline='', encoding='utf-8')\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(csv_header)\n",
    "except Exception as e:\n",
    "    print(f\"Error al abrir el CSV: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Variables de conteo y tracking (P4)\n",
    "frame_num = 0\n",
    "# Usamos 'sets' para contar solo los IDs únicos que aparecen\n",
    "tracked_ids = {\n",
    "    'person': set(),\n",
    "    'car': set(),\n",
    "    'motorcycle': set(),\n",
    "    'bus': set(),\n",
    "    'truck': set()\n",
    "}\n",
    "\n",
    "print(f\"Procesando video: {ruta_video_entrada}...\")\n",
    "print(\"--- ¡Pulsa 'q' en la ventana emergente para salir! ---\")\n",
    "\n",
    "# --- 4. PROCESAR VIDEO FRAME A FRAME ---\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_num += 1\n",
    "    frame_annotated = frame.copy()\n",
    "\n",
    "    # --- Tarea P4: Detectar y SEGUIR (Track) Vehículos y Personas ---\n",
    "    # Usamos model.track() en lugar de model.predict()\n",
    "    results_general = model_general_coches.track(\n",
    "        frame, \n",
    "        classes=coco_classes_of_interest, \n",
    "        conf=conf_vehiculo, \n",
    "        verbose=False, \n",
    "        persist=True # ¡Importante para mantener el tracking entre frames!\n",
    "    )\n",
    "\n",
    "    if results_general[0].boxes.id is not None:\n",
    "        # Iteramos sobre las cajas (boxes) del resultado\n",
    "        for box in results_general[0].boxes:\n",
    "            # Coordenadas y datos\n",
    "            coords = box.xyxy.cpu().numpy().astype(int)[0]\n",
    "            x1_v, y1_v, x2_v, y2_v = coords\n",
    "            conf_v = box.conf.cpu().numpy()[0]\n",
    "            class_id_v = int(box.cls.cpu().numpy()[0])\n",
    "            track_id = int(box.id.cpu().numpy()[0]) # <-- ¡Aquí está el ID de Tracking!\n",
    "            label_veh = model_general_coches.names[class_id_v]\n",
    "\n",
    "            # Tarea P4 (Conteo): Añadimos el ID al 'set'\n",
    "            if label_veh in tracked_ids:\n",
    "                tracked_ids[label_veh].add(track_id)\n",
    "\n",
    "            # Dibujar en el frame\n",
    "            label_display = f'ID: {track_id} ({label_veh})'\n",
    "            cv2.rectangle(frame_annotated, (x1_v, y1_v), (x2_v, y2_v), color_vehiculo_persona, 2)\n",
    "            cv2.putText(frame_annotated, label_display, (x1_v, y1_v - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color_vehiculo_persona, 2)\n",
    "\n",
    "            # Tarea P4 (CSV): Escribir en el CSV\n",
    "            # 'N/A' porque este objeto no es una matrícula\n",
    "            csv_writer.writerow([frame_num, label_veh, f\"{conf_v:.2f}\", track_id, x1_v, y1_v, x2_v, y2_v, 'N/A'])\n",
    "\n",
    "\n",
    "    # --- Tarea P4b: Detectar Matrículas y hacer OCR ---\n",
    "    # Para esto usamos predict(), no necesitamos tracking de la matrícula\n",
    "    results_matricula = model_matriculas.predict(frame, conf=conf_matricula, verbose=False)\n",
    "    \n",
    "    if len(results_matricula) > 0 and len(results_matricula[0].boxes) > 0:\n",
    "        for box_mat in results_matricula[0].boxes:\n",
    "            coords_mat = box_mat.xyxy.cpu().numpy().astype(int)[0]\n",
    "            mx1, my1, mx2, my2 = coords_mat\n",
    "            conf_m = box_mat.conf.cpu().numpy()[0]\n",
    "            label_mat = model_matriculas.names[0] # 'matricula'\n",
    "\n",
    "            # Tarea P4b (OCR): Recortar la matrícula y leerla\n",
    "            # Añadimos un pequeño margen (padding) como en tu script de OCR\n",
    "            crop_matricula = frame[\n",
    "                max(0, my1 - 5) : min(frame.shape[0], my2 + 5),\n",
    "                max(0, mx1 - 5) : min(frame.shape[1], mx2 + 5)\n",
    "            ]\n",
    "            \n",
    "            texto_ocr = \"N/A\"\n",
    "            if crop_matricula.size > 0: # Asegurarse de que el recorte no esté vacío\n",
    "                try:\n",
    "                    # Usamos la whitelist de tu script de OCR\n",
    "                    ocr_result = reader_easyocr.readtext(crop_matricula, detail=0, allowlist='0123456789ABCDEFGHIJKLMNPQRSTUVWXYZ')\n",
    "                    if ocr_result:\n",
    "                        texto_ocr = ocr_result[0].upper().replace(\" \", \"\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error en EasyOCR en frame {frame_num}: {e}\")\n",
    "            \n",
    "            # Dibujar en el frame (P4b)\n",
    "            label_display_ocr = f'{texto_ocr} ({conf_m:.2f})'\n",
    "            cv2.rectangle(frame_annotated, (mx1, my1), (mx2, my2), color_matricula, 2)\n",
    "            cv2.putText(frame_annotated, label_display_ocr, (mx1, my1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color_matricula, 2)\n",
    "\n",
    "            # Tarea P4b (CSV): Escribir en el CSV\n",
    "            # 'N/A' porque no tenemos un ID de tracking para la matrícula\n",
    "            csv_writer.writerow([frame_num, label_mat, f\"{conf_m:.2f}\", 'N/A', mx1, my1, mx2, my2, texto_ocr])\n",
    "\n",
    "\n",
    "    # --- 5. GUARDAR Y MOSTRAR ---\n",
    "    \n",
    "    # Guardar el fotograma procesado\n",
    "    out.write(frame_annotated)\n",
    "    \n",
    "    # Mostrar el video en ventana emergente\n",
    "    cv2.imshow('Deteccion en Vivo (P4 + P4b)', frame_annotated)\n",
    "\n",
    "    # Esperar 1ms y comprobar si se pulsa la tecla 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Detenido por el usuario.\")\n",
    "        break\n",
    "\n",
    "# --- 6. FINALIZACIÓN ---\n",
    "print(\"\\nLimpiando recursos...\")\n",
    "# Liberar los objetos de video\n",
    "cap.release()\n",
    "out.release()\n",
    "# Cerrar el archivo CSV\n",
    "csv_file.close()\n",
    "# Cerrar todas las ventanas de OpenCV\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Imprimir el conteo final (P4)\n",
    "print(\"\\n--- Conteo Final (IDs únicos detectados) ---\")\n",
    "total_general = 0\n",
    "for label, id_set in tracked_ids.items():\n",
    "    count = len(id_set)\n",
    "    print(f\"Total {label}s: {count}\")\n",
    "    total_general += count\n",
    "print(f\"Total objetos seguidos: {total_general}\")\n",
    "\n",
    "print(f\"\\nProceso de video completado.\")\n",
    "print(f\"Video guardado en: {ruta_video_salida}\")\n",
    "print(f\"Log CSV guardado en: {csv_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a62fa30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelos YOLO...\n",
      "Modelos YOLO cargados.\n",
      "Cargando EasyOCR (esto puede tardar un momento)...\n",
      "EasyOCR cargado.\n",
      "Procesando video: ./input_media/video.mp4...\n",
      "--- ¡Pulsa 'q' en la ventana emergente para salir! ---\n",
      "Detenido por el usuario.\n",
      "\n",
      "Limpiando recursos...\n",
      "\n",
      "--- Conteo Final (Cruce de Línea) ---\n",
      "Total Vehiculos contados al cruzar la línea: 0\n",
      "\n",
      "--- Conteo (Total IDs Únicos detectados) ---\n",
      "Total IDs unicos para persons: 1\n",
      "Total IDs unicos para cars: 3\n",
      "Total IDs unicos para motorcycles: 0\n",
      "Total IDs unicos para buss: 1\n",
      "Total IDs unicos para trucks: 0\n",
      "Total IDs unicos asignados: 5\n",
      "\n",
      "Proceso de video completado.\n",
      "Video guardado en: ./resultados_video/video_final_con_ocr_conteo.mp4\n",
      "Log CSV guardado en: ./resultados_video/log_detecciones.csv\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "\n",
    "# --- 1. CONFIGURACIÓN INICIAL ---\n",
    "\n",
    "# Cargar Modelos YOLO\n",
    "print(\"Cargando modelos YOLO...\")\n",
    "try:\n",
    "    model_general_coches = YOLO('yolov8n.pt')\n",
    "    ruta_modelo_matriculas = 'runs/detect/modelo_matriculas_yolo11/weights/best.pt'\n",
    "    model_matriculas = YOLO(ruta_modelo_matriculas)\n",
    "    print(\"Modelos YOLO cargados.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error cargando modelos YOLO: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Cargar EasyOCR (solo se hace una vez)\n",
    "print(\"Cargando EasyOCR (esto puede tardar un momento)...\")\n",
    "try:\n",
    "    reader_easyocr = easyocr.Reader(['es', 'en'], gpu=False) # False si no tienes GPU\n",
    "    print(\"EasyOCR cargado.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error cargando easyOCR: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Clases de interés (P4): 0=person, 2=car, 3=motorcycle, 5=bus, 7=truck\n",
    "coco_classes_of_interest = [0, 2, 3, 5, 7] \n",
    "# NUEVO: Clases que queremos contar al cruzar la línea\n",
    "vehicle_classes_to_count = [2, 3, 5, 7] # car, motorcycle, bus, truck\n",
    "\n",
    "# Colores y confianzas\n",
    "color_vehiculo_persona = (255, 0, 0) # Azul\n",
    "color_matricula = (0, 255, 0) # Verde\n",
    "color_linea_conteo = (0, 0, 255) # Rojo\n",
    "conf_vehiculo = 0.40\n",
    "conf_matricula = 0.1\n",
    "\n",
    "# --- 2. CONFIGURACIÓN DE ENTRADA Y SALIDA ---\n",
    "\n",
    "# Rutas de Vídeo\n",
    "ruta_video_entrada = './input_media/video.mp4'\n",
    "ruta_video_salida = './resultados_video/video_final_con_ocr_conteo.mp4'\n",
    "os.makedirs('./resultados_video', exist_ok=True)\n",
    "\n",
    "# Rutas de CSV (P4.6 y P4b)\n",
    "csv_output_path = './resultados_video/log_detecciones.csv'\n",
    "# Definimos el header del CSV\n",
    "csv_header = [\n",
    "    'fotograma', \n",
    "    'tipo_objeto',      # person, car, matricula\n",
    "    'confianza', \n",
    "    'id_tracking',      # 'N/A' para matrículas\n",
    "    'x1', 'y1', 'x2', 'y2', \n",
    "    'texto_matricula'   # 'N/A' para personas/vehículos\n",
    "]\n",
    "\n",
    "# --- 3. INICIALIZAR LECTORES Y ESCRITORES ---\n",
    "\n",
    "# Lector de Video\n",
    "cap = cv2.VideoCapture(ruta_video_entrada)\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: No se pudo abrir el video '{ruta_video_entrada}'\")\n",
    "    exit()\n",
    "\n",
    "# Escritor de Video\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(ruta_video_salida, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Escritor de CSV\n",
    "try:\n",
    "    csv_file = open(csv_output_path, 'w', newline='', encoding='utf-8')\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(csv_header)\n",
    "except Exception as e:\n",
    "    print(f\"Error al abrir el CSV: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Variables de conteo y tracking\n",
    "frame_num = 0\n",
    "# Usamos 'sets' para contar los IDs únicos que aparecen (CONTEO ANTIGUO, informativo)\n",
    "tracked_ids = {\n",
    "    'person': set(),\n",
    "    'car': set(),\n",
    "    'motorcycle': set(),\n",
    "    'bus': set(),\n",
    "    'truck': set()\n",
    "}\n",
    "\n",
    "# --- NUEVO: Variables para el Conteo por Cruce de Línea ---\n",
    "# Definimos la línea de conteo (horizontal, al 75% de la altura)\n",
    "line_y = int(frame_height * 0.75) \n",
    "# Diccionario para guardar la última posición 'y' de cada ID\n",
    "# Formato: { track_id: ultima_y }\n",
    "track_history = {} \n",
    "# Set para guardar los IDs que ya hemos contado\n",
    "counted_ids = set() \n",
    "# El nuevo contador\n",
    "vehicle_count = 0\n",
    "# --- Fin de variables nuevas ---\n",
    "\n",
    "\n",
    "print(f\"Procesando video: {ruta_video_entrada}...\")\n",
    "print(\"--- ¡Pulsa 'q' en la ventana emergente para salir! ---\")\n",
    "\n",
    "# --- 4. PROCESAR VIDEO FRAME A FRAME ---\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_num += 1\n",
    "    frame_annotated = frame.copy()\n",
    "    \n",
    "    # NUEVO: Set para guardar los IDs vistos en ESTE frame\n",
    "    current_frame_ids = set()\n",
    "\n",
    "    # --- Tarea P4: Detectar y SEGUIR (Track) Vehículos y Personas ---\n",
    "    results_general = model_general_coches.track(\n",
    "        frame, \n",
    "        classes=coco_classes_of_interest, \n",
    "        conf=conf_vehiculo, \n",
    "        verbose=False, \n",
    "        persist=True \n",
    "    )\n",
    "\n",
    "    if results_general[0].boxes.id is not None:\n",
    "        # Iteramos sobre las cajas (boxes) del resultado\n",
    "        for box in results_general[0].boxes:\n",
    "            # Coordenadas y datos\n",
    "            coords = box.xyxy.cpu().numpy().astype(int)[0]\n",
    "            x1_v, y1_v, x2_v, y2_v = coords\n",
    "            conf_v = box.conf.cpu().numpy()[0]\n",
    "            class_id_v = int(box.cls.cpu().numpy()[0])\n",
    "            track_id = int(box.id.cpu().numpy()[0]) # <-- ¡Aquí está el ID de Tracking!\n",
    "            label_veh = model_general_coches.names[class_id_v]\n",
    "\n",
    "            # NUEVO: Añadir ID al set de IDs del frame actual\n",
    "            current_frame_ids.add(track_id)\n",
    "\n",
    "            # --- NUEVO: Lógica de Conteo por Cruce de Línea ---\n",
    "            # Usamos el punto inferior central del bounding box (y2_v)\n",
    "            current_y = y2_v \n",
    "            \n",
    "            # Solo contamos las clases de vehículos\n",
    "            if class_id_v in vehicle_classes_to_count:\n",
    "                # 1. Comprobar si ya estábamos siguiendo este ID\n",
    "                if track_id in track_history:\n",
    "                    # 2. Obtener su posición anterior\n",
    "                    prev_y = track_history[track_id]\n",
    "                    \n",
    "                    # 3. Comprobar si ha cruzado la línea (de arriba hacia abajo)\n",
    "                    #    Y si NO lo hemos contado ya\n",
    "                    if prev_y < line_y and current_y >= line_y and track_id not in counted_ids:\n",
    "                        vehicle_count += 1\n",
    "                        counted_ids.add(track_id)\n",
    "                        print(f\"[CONTEO] Nuevo vehiculo (ID: {track_id}) cruzó. Total: {vehicle_count}\")\n",
    "                \n",
    "                # 4. Actualizar el historial de posición para este ID\n",
    "                track_history[track_id] = current_y\n",
    "            # --- Fin de la lógica de conteo ---\n",
    "\n",
    "\n",
    "            # Tarea P4 (Conteo ANTIGUO): Añadimos el ID al 'set'\n",
    "            if label_veh in tracked_ids:\n",
    "                tracked_ids[label_veh].add(track_id)\n",
    "\n",
    "            # Dibujar en el frame\n",
    "            label_display = f'ID: {track_id} ({label_veh})'\n",
    "            cv2.rectangle(frame_annotated, (x1_v, y1_v), (x2_v, y2_v), color_vehiculo_persona, 2)\n",
    "            cv2.putText(frame_annotated, label_display, (x1_v, y1_v - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color_vehiculo_persona, 2)\n",
    "\n",
    "            # Tarea P4 (CSV): Escribir en el CSV\n",
    "            csv_writer.writerow([frame_num, label_veh, f\"{conf_v:.2f}\", track_id, x1_v, y1_v, x2_v, y2_v, 'N/A'])\n",
    "\n",
    "    \n",
    "    # --- NUEVO: Limpiar el historial de IDs que ya no están en pantalla ---\n",
    "    # Esto evita que el diccionario track_history crezca indefinidamente\n",
    "    stale_ids = set(track_history.keys()) - current_frame_ids\n",
    "    for stale_id in stale_ids:\n",
    "        del track_history[stale_id]\n",
    "    # --- Fin de la limpieza ---\n",
    "\n",
    "\n",
    "    # --- Tarea P4b: Detectar Matrículas y hacer OCR ---\n",
    "    # (Esta parte no cambia)\n",
    "    results_matricula = model_matriculas.predict(frame, conf=conf_matricula, verbose=False)\n",
    "    \n",
    "    if len(results_matricula) > 0 and len(results_matricula[0].boxes) > 0:\n",
    "        for box_mat in results_matricula[0].boxes:\n",
    "            coords_mat = box_mat.xyxy.cpu().numpy().astype(int)[0]\n",
    "            mx1, my1, mx2, my2 = coords_mat\n",
    "            conf_m = box_mat.conf.cpu().numpy()[0]\n",
    "            label_mat = model_matriculas.names[0] # 'matricula'\n",
    "\n",
    "            # Tarea P4b (OCR)\n",
    "            crop_matricula = frame[\n",
    "                max(0, my1 - 5) : min(frame.shape[0], my2 + 5),\n",
    "                max(0, mx1 - 5) : min(frame.shape[1], mx2 + 5)\n",
    "            ]\n",
    "            \n",
    "            texto_ocr = \"N/A\"\n",
    "            if crop_matricula.size > 0: \n",
    "                try:\n",
    "                    ocr_result = reader_easyocr.readtext(crop_matricula, detail=0, allowlist='0123456789ABCDEFGHIJKLMNPQRSTUVWXYZ')\n",
    "                    if ocr_result:\n",
    "                        texto_ocr = ocr_result[0].upper().replace(\" \", \"\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error en EasyOCR en frame {frame_num}: {e}\")\n",
    "            \n",
    "            # Dibujar en el frame (P4b)\n",
    "            label_display_ocr = f'{texto_ocr} ({conf_m:.2f})'\n",
    "            cv2.rectangle(frame_annotated, (mx1, my1), (mx2, my2), color_matricula, 2)\n",
    "            cv2.putText(frame_annotated, label_display_ocr, (mx1, my1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color_matricula, 2)\n",
    "\n",
    "            # Tarea P4b (CSV)\n",
    "            csv_writer.writerow([frame_num, label_mat, f\"{conf_m:.2f}\", 'N/A', mx1, my1, mx2, my2, texto_ocr])\n",
    "\n",
    "\n",
    "    # --- 5. GUARDAR Y MOSTRAR ---\n",
    "    \n",
    "    # --- NUEVO: Dibujar la línea de conteo y el contador ---\n",
    "    cv2.line(frame_annotated, (0, line_y), (frame_width, line_y), color_linea_conteo, 2)\n",
    "    count_text = f\"Vehiculos Contados: {vehicle_count}\"\n",
    "    # Poner el texto en un fondo sólido para mejor legibilidad\n",
    "    (text_width, text_height), baseline = cv2.getTextSize(count_text, cv2.FONT_HERSHEY_SIMPLEX, 1.5, 3)\n",
    "    cv2.rectangle(frame_annotated, (10, 30), (10 + text_width, 30 + text_height + baseline), (0,0,0), -1) # Fondo negro\n",
    "    cv2.putText(frame_annotated, count_text, (10, 30 + text_height), cv2.FONT_HERSHEY_SIMPLEX, 1.5, color_linea_conteo, 3)\n",
    "    # --- Fin de dibujar línea y contador ---\n",
    "\n",
    "    # Guardar el fotograma procesado\n",
    "    out.write(frame_annotated)\n",
    "    \n",
    "    # Mostrar el video en ventana emergente\n",
    "    cv2.imshow('Deteccion y Conteo por Cruce de Linea', frame_annotated)\n",
    "\n",
    "    # Esperar 1ms y comprobar si se pulsa la tecla 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Detenido por el usuario.\")\n",
    "        break\n",
    "\n",
    "# --- 6. FINALIZACIÓN ---\n",
    "print(\"\\nLimpiando recursos...\")\n",
    "# Liberar los objetos de video\n",
    "cap.release()\n",
    "out.release()\n",
    "# Cerrar el archivo CSV\n",
    "csv_file.close()\n",
    "# Cerrar todas las ventanas de OpenCV\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Imprimir el conteo final (NUEVO)\n",
    "print(\"\\n--- Conteo Final (Cruce de Línea) ---\")\n",
    "print(f\"Total Vehiculos contados al cruzar la línea: {vehicle_count}\")\n",
    "\n",
    "# Imprimir el conteo antiguo (informativo)\n",
    "print(\"\\n--- Conteo (Total IDs Únicos detectados) ---\")\n",
    "total_general = 0\n",
    "for label, id_set in tracked_ids.items():\n",
    "    count = len(id_set)\n",
    "    print(f\"Total IDs unicos para {label}s: {count}\")\n",
    "    total_general += count\n",
    "print(f\"Total IDs unicos asignados: {total_general}\")\n",
    "\n",
    "print(f\"\\nProceso de video completado.\")\n",
    "print(f\"Video guardado en: {ruta_video_salida}\")\n",
    "print(f\"Log CSV guardado en: {csv_output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
